<!DOCTYPE html>
<html>

  <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG"></script>
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Алгоритм суммы-произведения и граф сомножителей. Часть 1.</title>
  <meta name="description" content="  Mood: The Mars Volta, «De-Loused in Comatorium»  Оценочное время: 60-90 минут.">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="/2016/03/03/sum-product-algorithm-part1-ru.html">
  
  <link rel="alternate" hreflang="en" href="/2016/03/03/sum-product-algorithm-part1.html" />
  <link rel="alternate" hreflang="ru" href="/2016/03/03/sum-product-algorithm-part1-ru.html" />
  
  <link rel="alternate" type="application/rss+xml" title="" href="">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/"></a>

    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>

      <div class="trigger">

        <!--<a class="page-link" href=""></a>-->
        
      </div>

      <!--
      <div class="trigger">
        
        
          
          <a class="page-link" href="/archive_ru.html">Записи</a>
          
        
          
        
          
          <a class="page-link" href="/old_site/index_ru.html">CV</a>
          
        
      </div>
      -->
    </nav>

  </div>


<div class="wrapper" style="text-align: right; line-height: 2em">
  
   <a href="/2016/03/03/sum-product-algorithm-part1.html" class="en">en</a>  <a href="/2016/03/03/sum-product-algorithm-part1-ru.html" class="ru">ru</a> 

  
  
</div>

</header>


    <div class="page-content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">Алгоритм суммы-произведения и граф сомножителей. Часть 1.</h1>
    <p class="post-meta"><time datetime="2016-03-03T00:00:00+01:00" itemprop="datePublished">Mar 3, 2016</time></p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <ul>
  <li>Mood: <a href="https://music.yandex.ru/album/215667" target="_blank">
The Mars Volta, «De-Loused in Comatorium»
</a></li>
  <li>Оценочное время: 60-90 минут.</li>
</ul>

<h1 id="о-чём-эта-запись">О чём эта запись?</h1>

<p>В Москве мы проводили для студентов МГУ, ВШЭ, МФТИ, ИППИ совместный семинар по <a href="http://www.machinelearning.ru/wiki/index.php?title=Статистический_кластерный_анализ_(регулярный_семинар)">статистическому кластерному
анализу</a>.
Недавно я делал доклад на тему алгоритма суммы-произведения и графа сомножителей (sum-product algorithm and factor graphs).
Я никогда не занимался этой темой, но удачным образом доклад породил интересную
дискуссию про то, как используются байесовские методы и статистическая физика в
обработке изображений. Поверхностный поиск выдал мне несколько книг по теме (обе
на русском):
<a href="http://www.jip.ru/2013/141-170-2013.pdf">(1) случайное поле Гиббса</a> и
<a href="http://osmf.sscc.ru/~smp/Winkler-2rus-2008.pdf">(2) случайные поля и марковские цепи в обработке изображений</a>.
Первая книга написана полностью на языке теоретической физики, вторая больше про
обработку изображений и про байесовскую статистику.</p>

<p>Текущая заметка основана на статье «<a href="http://vision.unipv.it/IA2/Factor%20graphs%20and%20the%20sum-product%20algorithm.pdf">Factor Graphs and the Sum-Product Algorithm (2001)</a>»
за авторством Kschischang, Frey, Loeliger. Изначально мой интерес в этой статье
был основан на том, что мы хотели понять, как работает известный алгоритм
кластеризации  «<a href="https://en.wikipedia.org/wiki/Affinity_propagation">Affinity Propagation</a>».
Авторы Frey и Dueck придумали этот алгоритм и опубликовали про него несколько
работ. Алгоритм Affinity Propagation весьма схож с алгоритмом В.Г.Спокойного Adaptive Weight Clustering, 
над которым мы тогда работали, 
и мы хотели узнать «врага в лицо».</p>

<p>Оказалось, что идея графа сомножителей является куда более общей, чем просто один
алгоритм кластеризации, и содержит красивые математические идеи.
Чем отличается эта заметка от оригинальной статьи? Я постараюсь заострить
внимание на моментах, которые вызвали наибольший интерес в течение семинара, и
пропущу доказательства и технические подробности. Стоит заметить, что статья
написана очень хорошим и понятным языком, так что мне почти ничего не нужно
делать. Часть материала просто скопирована дословно.</p>

<p>Предупрежу читателя, что, как сказано выше, я не специалист в байесовской теории
и графических моделях. Скорее всего я не чувствую каких-то естественных
аналогий, и буду рад, если мне на это укажут в комментариях!</p>

<p>Алгоритм суммы-произведения является обобщением нескольких других известных алгоритмов:
Forward-Backward Algorithm, алгоритма Витерби для марковских цепей, фильтра Калмана,
быстрого преобразования Фурье и нескольких алгоритмов из теории линейного
кодирования. Это довольно длинный список, но я постараюсь объяснить, как
довольно несложная модель передачи сообщений в двудольном графе может объединять
все эти понятия. Данная заметка покрывает только первую часть доклада, поэтому
мы обсудим только одно приложение.</p>

<h1 id="алгоритм-суммы-произведения-для-маргинальных-функций">Алгоритм суммы-произведения для маргинальных функций</h1>

<p>Давайте начнём с такой задачи.
Пусть
\( x_1, \ldots, x_n \) это набор переменных, где каждая переменная принимает значения
только в конечном алфавите 
\( \Sigma \).
Пусть  \( g(x_1, \ldots, x_n) \) некоторая функция, принимающая вещественные значения с некоторой дополнительной внутренней структурой, которую мы обсудим позже.
Мы хотим вычислить так называемые <em>маргинальные</em> функции:
\[
    g_i(x_i) \overset{def}= \sum_{x_1} \cdots \sum_{x_{i-1}} \sum_{x_{i+1}} \cdots \sum_{x_{n}} g(x_1, \ldots, x_n),
\]
где значение \( g_i(a) \) получается суммированием функции \( g(x_1, \ldots, x_n) \)
по всем значениях переменных с условием \( x_i = a \).
Авторы оригинальной статьи придумали специальное обозначение для сумм такого
рода:
\[
    g_i (x_i) = \sum_{\sim \{ x_i \}} g(x_1, \ldots, x_n)
\]
Например, если \( h \) это функция от трёх переменных, то
\[
    h_2(x_2) = \sum_{\sim \{ x_2 \}} h(x_1, x_2, x_3) = \sum_{x_1} \sum_{x_3} h(x_1, x_2, x_3).
\]
Вообще говоря, необходимо экспоненциальное число шагов для того, чтобы вычислить
такую функцию. Нам нужны некоторые дополнительные предположения про устройство
функции \( g \). Давайте предположим, что функция \( g(x_1, \ldots, x_n) \)
раскладывается в произведение нескольких <em>локальных функций</em>, то есть
\[
    g(x_1, \ldots, x_n) = \prod_{j \in J} f_j (X_j),
\]
где каждое \( X_j \) является подмножеством \( \{ x_1, \ldots, x_n \} \), и \( J \) является дискретным множеством индексов.
Ниже мы рассмотрим пример.</p>

<p>Почему эта задача является интересной? Почему мы рассматриваем именно такую
структуру? Часто ли на практике встречаются функции такого вида?</p>

<p>Как сказать, позже мы покажем, что такие разложения встречаются довольно часто в
разных задачах, как и было обещано в начале заметки. Тем не менее, задача
нахождения маргинальных сумм является только одной из нескольких возможностей.
Как только мы поймём идею маргинальных сумм, можно будет рассмотреть более общий
класс задач в произвольных кольцах.</p>

<blockquote>
  <p><strong>Определение.</strong></p>

  <p><em>Графом сомножителей</em> называется двудольный граф, который представляет структуру факторизации. Первая доля содержит вершины, соответствующие переменны, вторая доля — функциям.
Между вершинами, соответствующими переменной \( x_i \) и функции \( f_j \) (последняя называется <em>вершиной-сомножителем</em>) есть ребро тогда и только тогда, когда
\( x_i \) входит в функцию \( f_j \) как аргумент.</p>
</blockquote>

<blockquote>
  <p><strong>Пример.</strong></p>

  <p>Пусть \[ g(x_1, x_2, x_3, x_4, x_5) = f_A(x_1) f_B(x_2) f_C(x_1, x_2, x_3) f_D(x_3, x_4) f_E(x_3, x_5). \]
Тогда соответствующий граф сомножителей изображён на рисунке:</p>

</blockquote>
<center>
<img src="/pic/factor_graphs/2016-03-03-1.png" />

</center>

<h2 id="дерево-выражения">Дерево выражения</h2>

<p>Если граф сомножителей не содержит циклов, то его можно представить в виде
дерева.</p>

<center>
<img src="/pic/factor_graphs/2016-03-03-3.png" />
</center>

<p>Разумеется, произвольный граф сомножителей не всегда можно представить в виде
дерева, потому что он может содержать циклы. Мы начнём со случая, где граф
сомножителей является деревом, а потом обсудим, как можно перейти к общему
случаю. На практике самое интересное происходит как раз тогда, когда циклы есть!</p>

<p>Описанная ситуация может быть использована для того, чтобы упростить вычисления
используя закон дистрибутивности. Пусть мы хотим найти \( g_1(x_1) \)  из предыдущего примера.
Тогда сперва мы вычисляем маргинальные суммы для вершин \( x_4, x_5 \), затем «передаём сообщения»
от \( f_D, f_E \) к вершине \( x_3 \) (позже мы поймём, что именно означает передать сообщение),
затем вычисляем маргинальные суммы для \( x_3 \), и так далее.</p>

<p>Более формально, используя закон дистрибутивности, маргинальная сумма для \( g_1(x_1) \) может быть представлена в виде
\[
    g_1 (x_1) = f_A (x_1) 
    \Big( \sum_{x_2} f_B(x_2) 
    \Big( \sum_{x_3} f_C(x_1, x_2, x_3) 
    \Big( \sum_{x_4} f_D(x_3, x_4)
    \Big) 
    \Big( \sum_{x_5} f_E(x_3, x_5)
    \Big)
    \Big) 
    \Big)
\]
Более того, используя обозначение исключающего суммирования \( \sum_{\sim \{ x \}} \) вместо \(\sum_{x}\), 
та же самая сумма может быть представлена в виде
\[
    g_1(x_1) = f_A (x_1) \sum_{\sim \{x_1 \}} \Big(
    f_B(x_2)f_C(x_1, x_2, x_3)<br />
    \Big(
        \sum_{\sim \{x_3\}} f_D(x_3, x_4)
    \Big)
    \Big(
        \sum_{\sim \{x_3\}} f_E(x_3, x_5)
    \Big)
    \Big)
\]</p>

<p>Проверка корректности выражения выше может занять некоторое время.</p>

<blockquote>
  <p><strong>Упражнение.</strong></p>

  <p>Напишите аналогичную декомпозицию для \( g_3 (x_3) \).</p>
</blockquote>

<blockquote>
  <p><strong>Предложение.</strong></p>

  <p>Если граф сомножителей не содержит циклов, то граф сомножителей не только
кодирует представление глобальной функции, но также даёт алгоритм для быстрого
вычисления маргинальных функций.</p>
</blockquote>

<blockquote>
  <p><strong>Упражнение.</strong></p>

  <p>Верно ли, что вычисления ускоряются по сравнению с методом «грубой силы»?</p>
</blockquote>

<h2 id="вычисление-маргинальных-функций">Вычисление маргинальных функций</h2>

<p>До сих пор, дерево было «подвешено» за вершину \( x_1 \), мы мы могли вычислить маргинальную сумму \( g_1(x_1) \).
Если мы хотим вычислить, скажем, маргинальную сумму \( g_3(x_3) \), текущая техника позволяет только подвесть заново это дерево за другую вершину
и проделать всю процедуру разложения заново. Сперва мы поймём, как сделать
процесс автоматическим для одной маргинальной суммы, а затем модифицируем
процедуру таким образом, чтобы считать все маргинальные суммы.</p>

<p>Для того, чтобы вычислить все маргинальные функции, мы инициируем процесс
передачи сообщений в листьях. Каждая вершина ждёт, пока она получит сообщения от
своих потомков, то есть остаётся в состоянии ожидания до тех пор, пока не придут
сообщения со всех смежных рёбер кроме одного.</p>

<p>Что является <em>сообщением</em>? Рассмотрим ребро \( \{x, f\} \), соединяющее переменную \( x\) с вершиной-сомножителем \( f\).
Независимо от того, куда смотрит ребро, в качестве сообщения мы будем
рассматривать некоторую функцию от одной переменной \( x\), скажем, \( \varphi_{ \{x, f\} }(x) \).
Каждая вершина получает сообщения, и затем отсылает сообщения.</p>

<p>Как уже говорилось, мы инициализируем процесс в листьях дерева. В течение
инициализации, каждая листовая вершина, соответствующая <em>переменной</em> \( x\),
посылает тождественную функцию (\( \varphi(x) \equiv 1 \)) в качестве сообщения своему родителю,
а каждая листовая <em>вершина-сомножитель</em> \( f\) посылает описание \( f \) своему родителю.
Заметим, что если \( f\) является листовой вершиной, то функция \( f\) 
зависит ровно от одной переменной.</p>

<p>Введём следующие правила обновления состояний:</p>

<center>
<img src="/pic/factor_graphs/2016-03-03-2.png" />
</center>

<p>В течение каждого шага, каждая вершина-переменная ожидает сообщений от всех
своих потомков, а затем просто посылает произведение сообщений, полученных от
них.</p>

<p>Вершина-сомножитель \( f \) с родителем \( x \)
формирует произведение \( f \) с сообщениями, полученными от потомков,
а затем действует на результат оператором \( \sum_{\sim \{ x \}} \) исключающего суммирования.</p>

<p>Пусть \( n(v) \) обозначает множество соседей заданной вершины 
\( v\).
Вычисление сообщений можно изобразить следующим образом:</p>

<h3 id="от-переменной-к-локальной-функции">от переменной к локальной функции</h3>
<p>\[
    \mu_{x \to f} (x) = \prod_{h \in n(x) \backslash \{f\}} \mu_{h \to x} (x)
\]</p>

<h3 id="от-локальной-функции-к-переменной">от локальной функции к переменной</h3>
<p>\[
    \mu_{f \to x} (x) = \sum_{\sim \{x\}} \Big(
    f(X) \prod_{y \in n(f) \backslash \{x\}} \mu_{y \to f} (y)
    \Big)
\]</p>

<p>Согласно этой схеме, вычисление заканчивается в корневой вершине \( x_i \),
потому что дерево подвешено за вершину \( x_i \). 
Конечная маргинальная функция \( g_i (x_i) \) получается как произведение всех сообщений,
полученных в \( x_i \).</p>

<blockquote>
  <p><strong>Упражнение.</strong></p>

  <p>Проверьте, что для примера, указанного выше, предложенная схема передачи сообщений приводит к правильному разложению для \( g_1(x_1) \).</p>
</blockquote>

<p>Описанная процедура хороша, если мы хотим только одну маргинальную сумму.
Давайте подумаем, как можно модифицировать её для нескольких маргиналов.</p>

<p>Если мы хотим вычислить все маргиналы, то не нужно фиксировать никакую вершину в
качестве корневой. Другими словами, между вершинами больше не будет соотношений
потомок-предок. Необходимо изменить схему передачи сообщений.</p>

<p>Теперь мы снова инициируем процесс передачи сообщений в листовых вершинах. И
снова, каждая вершина остаётся в состоянии ожидания до тех пор, пока не получит
сообщения от всех смежных вершин кроме одной. Как только сообщения получены, эта
вершина может вычислить сообщение и послать его по оставшемуся ребру своему
соседу. После отправки сообщения, данная вершина возвращается в состояние
ожидания, и ждёт обратного сообщения по этому ребру. Как только сообщение
получено, вершина может вычислить и послать сообщения остальным соседям.
Алгоритм завершается как только по каждому ребру было передано по два сообщения,
по одному в каждом направлении.</p>

<center>
<img src="/pic/factor_graphs/2016-03-03-4.png" />
</center>

<h2 id="пример-процедуры-передачи-сообщений">Пример процедуры передачи сообщений</h2>

<p>Для функции, упомянутой в одном из первых примеров, можно изобразить, в каком
порядке передаются сообщения:</p>

<center>
<img src="/pic/factor_graphs/2016-03-03-5.png" />
</center>

<p>Если подробнее, сообщения генерируются таким образом:</p>
<h4 id="шаг-1">Шаг 1.</h4>
<p>\begin{align}
    \mu_{A \to 1} (x_1) &amp;= \sum_{\sim \{x_1 \}} f_A(x_1) = f_A (x_1)  \<br />
    \mu_{B \to 2} (x_2) &amp;= \sum_{\sim \{x_2 \}} f_B(x_2) = f_B (x_2)  \<br />
    \mu_{4 \to D} (x_4) &amp;= 1                                                  \<br />
    \mu_{5 \to E} (x_5) &amp;= 1.
\end{align}</p>
<h4 id="шаг-2">Шаг 2.</h4>
<p>\begin{align}
    \mu_{1 \to С} (x_1) &amp;= \mu_{A \to 1} (x_1)  \<br />
    \mu_{2 \to С} (x_2) &amp;= \mu_{B \to 2} (x_2)  \<br />
    \mu_{D \to 3} (x_3) &amp;= \sum_{\sim \{x_3\}} \mu_{4 \to D} (x_4) f_D (x_3, x_4)                                                  \<br />
    \mu_{E \to 3} (x_3) &amp;= \sum_{\sim \{x_3\}} \mu_{5 \to E} (x_5) f_E (x_3, x_5) .
\end{align}</p>

<h4 id="шаг-3">Шаг 3.</h4>
<p>\begin{align}
    \mu_{C \to 3} (x_3) &amp;= \sum_{\sim \{x_3\}} \mu_{1 \to C} (x_1) \mu_{2 \to C} (x_2) f_C (x_1, x_2, x_3) \<br />
    \mu_{3 \to C} (x_3) &amp;= \mu_{D \to 3} (x_3) \mu_{E \to 3}  (x_3)
\end{align}</p>

<h4 id="шаг-4">Шаг 4.</h4>
<p>\begin{align}
    \mu_{C \to 1} (x_1) &amp;= \sum_{\sim \{x_1\}} \mu_{3 \to C} (x_3) \mu_{2 \to C} (x_2) f_C (x_1, x_2, x_3) \<br />
    \mu_{C \to 2} (x_2) &amp;= \sum_{\sim \{x_2\}} \mu_{3 \to C} (x_3) \mu_{1 \to C} (x_1) f_C (x_1, x_2, x_3) \<br />
    \mu_{3 \to D} (x_3) &amp;= \mu_{C \to 3} (x_3) \mu_{E \to 3} (x_3) \<br />
    \mu_{3 \to E} (x_3) &amp;= \mu_{C \to 3} (x_3) \mu_{D \to 3} (x_3).
\end{align}</p>

<h4 id="шаг-5">Шаг 5.</h4>

<p>\begin{align}
    \mu_{1 \to A} (x_1) &amp;= \mu_{C \to 1} (x_1) \<br />
    \mu_{2 \to B} (x_2) &amp;= \mu_{C \to 2} (x_2) \<br />
    \mu_{D \to 4} (x_4) &amp;= \sum_{\sim \{x_4\}} \mu_{3 \to D} (x_3) f_D (x_3, x_4)                                                  \<br />
    \mu_{E \to 4} (x_5) &amp;= \sum_{\sim \{x_5\}} \mu_{3 \to E} (x_3) f_E (x_3, x_5)                                                  \<br />
\end{align}</p>

<h4 id="завершение">Завершение.</h4>

<p>\begin{align}
    g_1(x_1) &amp;= \mu_{A \to 1} (x_1) \mu_{C \to 1} (x_1)\<br />
    g_2(x_2) &amp;= \mu_{B \to 2} (x_2) \mu_{C \to 2} (x_2)\<br />
    g_3(x_3) &amp;= \mu_{C \to 3} (x_3) \mu_{D \to 3} (x_3) \mu_{E \to 3} (x_3)\<br />
    g_4(x_4) &amp;= \mu_{D \to 4} (x_4) \<br />
    g_5(x_5) &amp;= \mu_{E \to 5} (x_5)
\end{align}</p>

<h1 id="некоторые-замечания">Некоторые замечания</h1>

<h2 id="трюк-с-полукольцом">Трюк с полукольцом</h2>

<p>Можно заметить, что маргинальные суммы используют две операции: \( \{+, \times\} \)
и эти две операции удовлетворяют закону дистрибутивности. Фактически, можно
использовать <em>любые</em> две операции, которые удовлетворяют закону
дистрибутивности, как это выполнено в случае <em>коммутативного полукольца</em>.
Например, если мы хотим найти максимум \( \max f(x_1, \ldots, x_n) \),
можно использовать набор операций \( \{\max, \times\} \), где \( \max \) теперь играет роль суммы.
Это позволяет сформулировать новый оптимизационный алгоритм в терминах графов
сомножителей!</p>

<h2 id="графы-сомножителей-с-циклами">Графы сомножителей с циклами</h2>

<p>Если мы хотим разрешить циклы в графах, то у нас больше не будет простого
условия завершения алгоритма, и следовательно, по каждому ребру в каждом
направлении может быть передано более одного сообщения, и это нормально.
Многие интересные приложения включают ситуации, когда граф таки <em>имеет циклы</em>.</p>

<p>Давайте условимся, что каждая вершина должна передавать сообщения вдоль каждого
ребра постоянно, предполагая, что передача сообщений синхронизирована с некими
«глобальными часами». Фактически, существует множество возможных механизмов
планирования сообщений, и несколько таких стратегий описано в оригинальной
статье.</p>

<p>Важно подчеркнуть, что теперь мы не инициализируем вершины, а вместо этого
инициализируем рёбра. Теперь, в течение инициализации мы предполагаем, что 
каждое ребро заряжено сообщением с единицей.</p>

<blockquote>
  <p><strong>Упражнение.</strong></p>

  <p>Проверьте, что если граф сомножителей не имеет циклов, то такая инициализация не повлияет на конечный результат, и не повлияет на число шагов до сходимости алгоритма.</p>
</blockquote>

<p>Итак, граф сомножителей полученный из функции \( g \), содержит циклы. Какие
гарантии можно получить для такого алгоритма? Оказывается, что каждая итерация
алгоритма суммы-произведения минимизирует так называемую <em>дивергенцию
Кульбака-Лейблера</em>. То есть, существует полуинвариант, который минимизируется
нашей процедурой. Давайте поймём, что происходит, шаг за шагом.</p>

<h1 id="метод-бете">Метод Бете</h1>

<p>Следующая теорема утверждает, что в вероятностных распределениях есть некоторая
структура, которая может быть представлена в виде произведения, если граф
сомножителей не имеет циклов.</p>

<blockquote>
  <p><strong>Предложение</strong> (Аппроксимация среднего поля)</p>

  <p>Обозначим через \( N(a) \) множество аргументов функции с индексом \( a\), и через \( d_i \) мощность множества соседей \( x_i \).</p>

  <p>Предположим, что \( p(\boldsymbol x) \) задаёт вероятностное распределение в виде произведения, где
\[
  p(\boldsymbol x) = \prod_{a = 1}^{M} q_a(\boldsymbol x_{N(a)})
\]
и соответствующие граф не имеет циклов.
Тогда это распределение можно представить в виде
\[
  p(\boldsymbol x) = \dfrac{\prod_{a=1}^M p_a(\boldsymbol x_{N(a)})}{\prod_{i=1}^N (p_i(x_i))^{d_i - 1}},<br />
\]
где функции \( p_n (x_n) \) и \( p_{a}(\boldsymbol x_{N(a)}) \) подчиняются ограничениям
\begin{align}
    \sum_{x_n} p_n (x_n) &amp;= 1 \quad \forall n \in [1, N], \<br />
    \sum_{\boldsymbol x_{N(a)}} p_a(\boldsymbol x_{N(a)}) &amp;= 1,\<br />
    \sum_{\boldsymbol x_{N(a) \backslash n}} p_a(\boldsymbol x_{N(a)}) &amp;= p_n(x_n) \quad \forall n \in [1, N].
\end{align}</p>
</blockquote>

<blockquote>
  <p><strong>Упражнение.</strong></p>

  <p>Найдите разложение Бете для функции из нашего примера, предполагая, что наша функция задаёт вероятностное распределение.</p>
</blockquote>

<p>Напомню, что все переменные \( x_1, \ldots, x_n \) принимают значения лишь в конечном алфавите \( \Sigma \).
Это означает, что любая функция от одной переменной \( x_i \) может быть представлена в виде вектора длины \( |\Sigma| \).
Это значит, что разложение Бете может быть параметризовано с помощью
фиксированного набора параметров.</p>

<blockquote>
  <p><strong>Теорема.</strong></p>

  <p>Если граф сомножителей, соответствующий \(p(\boldsymbol x)\) имеет циклы, то шаги алгоритма суммы-произведения эквивалентны координатному спуску для дивергенции Кульбака-Лейблера (KL-дивергенции) между \( p(\boldsymbol x)\) и распределением типа Бете.</p>
</blockquote>

<p>Доказательство и точную формулировку можно найти в приложении A <a href="http://www.cs.columbia.edu/~delbert/docs/DDueck-thesis_small.pdf">диссертации Delbert Dueck</a>.</p>

<p>Теперь мы можем перейти к приложениям.</p>

<h1 id="моделирование-систем-с-помощью-графов-сомножителей">Моделирование систем с помощью графов сомножителей</h1>

<h2 id="affinity-propagation">Affinity propagation.</h2>

<p>Affinity propagation (распространение сродства) это алгоритм кластеризации. Его
цель состоит в том, чтобы максимизировать функционал <em>net similarity</em>.</p>

<p>Сформулируем задачу следующим образом: задана последовательность наблюдений \( X_1, \ldots, X_n \), а также матрица схожести (это как расстояния только наоборот) \( s(i, j) \). Часто бывает так, что мы не можем наблюдать сами переменные \( X_1, \ldots, X_n \), но мы всегда можем наблюдать матрицу схожести.</p>

<p>В задаче метрической кластеризации, то есть когда \( X_j \in \mathbb R^d\), можно выбрать схожесть по правилу \( s(i, j) = - d(X_i, X_j) \) для \( i \neq j\), однако для \( i = j\) необходимо, чтобы \( s(X_i, X_j) \neq 0 \). Фактически, существует несколько возможных стратегий для того, чтобы определить матрицу схожести вершины с самой собой:
\[
    s(i, i) = -\lambda; \quad \text{or} \quad
    s(i, i) = \mathrm{Median}_{j}(s(i, j))
\]                           <br />
Среди наблюдений 
 \( c_i \in \{X_1, \ldots, X_n \} \) 
мы выбираем так называемые <em>экземпляры</em>  \( c_1, c_2, \ldots, c_n \) 
так, чтобы сумма схожестей 
\[
    \sum_{i = 1}^{n} s(i, c_i)
\]
была максимальной. При этом есть одно ограничение, которое препятствует
«жадному» назначению экземпляров.
\[
    (c_i = k) \, \Rightarrow \, (c_k = k),
\] 
Необходимо, чтобы назначенные экземпляры были корректными в том смысле, что если
точка \( X_k \) является экземпляром для точки \( X_i \), то она должна являться экземпляром для самой себя.
Это требование можно переформулировать следующим образом: множество точек
разбито на непересекающиеся подмножества точек, где каждое подмножество имеет
свой собственный единственный экземпляр.</p>

<center>
<img src="/pic/factor_graphs/2016-03-03-7.png" alt="Reference: Brendan J. Frey and Delbert Dueck, Clustering by Passing Messages Between Data Points, Science Feb. 2007" /> <br />
Reference: Brendan J. Frey and Delbert Dueck, “Clustering by Passing Messages Between Data Points”, Science Feb. 2007
</center>

<p>Такая оптимизационная задача может быть проинтерпретирована как <a href="https://en.wikipedia.org/wiki/Facility_location_problem"><em>проблема размещения объектов (facility Location Problem)</em></a>, и она является NP-трудной.</p>

<p>Оказывается, что целевая функция вместе с ограничением корректности может быть
преобразована в некоторую другую функцию без ограничений. А именно, мы
рассматриваем
\[
    F(\boldsymbol c, \boldsymbol s) = \prod_{i=1}^{N} e^{s(i, c_i)} \prod_{k=1}^{N} f_k (\underbrace{c_1, \ldots, c_N}_{\boldsymbol c})
\]
Второй член содержит ограничение корректности, определённое следующим образом:
\[
    f_k(\boldsymbol c) = \begin{cases}
    0, &amp; c_k \neq k, \, \exists i \colon c_i = k\<br />
    1, &amp; \mathrm{otherwise}
\end{cases}
\]</p>

<p>Такая функция естественным образом определяет граф сомножителей:</p>
<center>
<img src="/pic/factor_graphs/2016-03-03-8.png" />
</center>

<p>Фактически, анализ механизма передачи сообщений для функции \( F(\boldsymbol c, \boldsymbol s) \) является довольно запутанным, необходимо рассматривать несколько случаев
для корректных и некорректных конфигураций. Передача сообщений между \( c_i\) и \( f_j \) является наиболее важной, в то время как сообщения между \( s(i, c_i) \) и \( c_i \)
можно легко исключить. Авторы алгоритма Affinity Propagation доказывают, что
процедуру передачи сообщений, после некоторого преобразования обозначений, можно представить
в следующем виде:</p>

<blockquote>
  <p><strong>Affinity Propagation</strong></p>

  <ol>
    <li>Set \( a(i, k) \) to zero (availabilities).</li>
    <li>Repeat until convergence:
      <ul>
        <li>\( \forall i, k \colon r(i, k) = s(i, k) - \max_{k’ \neq k} [s(i, k’) + a(i, k’)] \)</li>
        <li>\( \forall i, k \colon a(i, k) = \begin{cases}
  \sum_{i’ \neq i} [r(i’, k)]_{+}, &amp; k = i\<br />
  [r(k,k) + [r(i’, k)]_{+}]_{-}, &amp; k \neq i
  \end{cases} \)</li>
      </ul>
    </li>
    <li>Output: cluster assignments.
      <ul>
        <li>\( \hat{\boldsymbol c} = (\hat c_{1}, \ldots, \hat c_{N}) \), where</li>
        <li>\( \hat c_i = \arg\max_{k} [a(i,k) + r(i,k)] \)</li>
      </ul>
    </li>
  </ol>
</blockquote>

<p>Конечно же, представленный алгоритм является эвристическим и не имеет
теоретического обоснования по следующим причинам:</p>

<ul>
  <li>В то время, как существует обоснование с помощью дивергенции Кульбака-Лейблера лишь для алгоритма суммы-произведения, про алгоритм максимума-произведения ничего не известно.
При этом использование алгоритма суммы-произведения для алгоритма affinity propagation не
имеет большого смысла потому что это не соответствует формулировке никакой
задачи, и к тому же вычислительно труднее, чем максимум-произведение.</li>
  <li>Алгоритм вообще может сойтись к некорректной конфигурации. В этом случае необходимо его перезапустить, до тех пор пока не получится корректная конфигурация. Не существует никаких теоретических гарантий на число перезапусков.</li>
</ul>

<p>Тем не менее, утверждается, что этот алгоритм хорошо себя ведёт на практике.</p>

<p>Заинтересованный читатель может обратиться к официальному FAQ, которое включает
некоторые вероятностные интерпретации affinity propagation: <a href="http://www.psi.toronto.edu/affinitypropagation/faq.html">FAQ Page</a>.</p>


    <div id="disqus_thread"></div>
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES * * */
    var disqus_shortname = 'electrictric-github';
    
    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

  </div>

</article>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading"></h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li></li>
          <li><a href="mailto:"></a></li>
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/electric-tric"><span class="icon icon--github"><svg viewBox="0 0 16 16"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">electric-tric</span></a>

          </li>
          

          
        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p></p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
